# CNN vs Vision Transformer Benchmark

A performance comparison of CNN and Vision Transformer architectures on CIFAR-10 image classification.

## ğŸ¯ Project Overview

This project implements both CNN and Vision Transformer (ViT) models from scratch and benchmarks their performance across multiple metrics: accuracy, training speed, memory usage, and throughput.

## ğŸ“Š Key Results

![Training Results](benchmark_results/efficiency_metrics.png)
![Training Results](benchmark_results/memory_comparison.png)
![Training Results](benchmark_results/performance_comparison.png)
![Training Results](benchmark_results/timing_breakdown.png)

| Model | Accuracy | Training Time | Memory | Parameters |
|-------|----------|---------------|---------|------------|
| **CNN** | 63.47% | 1069s | 26 MB | 98K |
| **ViT-small** | 30.41% | 4813s | 184 MB | 14.2M |

**Key Findings:**
- CNN trains **4.7Ã— faster** and uses **7Ã— less memory**
- CNN achieves **2Ã— higher accuracy** on CIFAR-10
- ViT underperforms due to small dataset size (50K images) - needs 1M+ images to excel

## ğŸ› ï¸ Technologies Used

- **PyTorch** - Deep learning framework
- **CUDA** - GPU acceleration
- **Mixed Precision Training** - Memory optimization
- **NumPy, Matplotlib, Seaborn** - Data analysis and visualization

## ğŸš€ Quick Start

```bash
# Install dependencies
pip install torch torchvision numpy matplotlib seaborn einops psutil

# Run benchmark
python benchmark_runner.py
```

## ğŸ“ Project Structure

```
â”œâ”€â”€ cnn_model.py           # CNN implementation
â”œâ”€â”€ vit_model.py           # Vision Transformer implementation
â”œâ”€â”€ benchmark_runner.py    # Benchmarking framework
â”œâ”€â”€ model_profiler.py      # Performance profiling
â””â”€â”€ data_utils.py          # CIFAR-10 data loading
```

## ğŸ”¬ Model Architectures

### CNN
- 3 convolutional blocks with max pooling
- Fully connected layers with dropout
- 98K parameters

### Vision Transformer
- Patch embedding (4Ã—4 patches)
- Multi-head self-attention (8 heads)
- 6-12 transformer blocks
- 14M+ parameters

## ğŸ’¡ Key Insights

**Why CNN outperformed ViT:**
1. **Dataset size** - CIFAR-10 (50K images) is too small for ViT (needs 1M+)
2. **Image resolution** - 32Ã—32 pixels provides only 64 patches for attention
3. **Inductive bias** - CNN's built-in translation equivariance helps with limited data
4. **Model size** - ViT is undertrained (14M params on 50K samples)

**When to use each:**
- **CNN**: Small datasets, limited compute, faster inference needed
- **ViT**: Large datasets (1M+ images), sufficient compute, transfer learning

## ğŸ“ˆ Generated Outputs

The benchmark generates:
- Accuracy comparison plots
- Memory usage analysis
- Training time breakdown
- Efficiency metrics (accuracy/time/memory)
- JSON report with detailed metrics

## ğŸ“ Learning Outcomes

- Implemented Vision Transformer with self-attention from scratch
- Built automated performance profiling framework
- Analyzed model-dataset fit and computational trade-offs
- Optimized training with mixed precision and GPU acceleration
